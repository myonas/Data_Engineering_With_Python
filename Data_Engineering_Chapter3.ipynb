{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is chapter 3 of Data Engineering with python practice code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One of the most basic tasks in data engineering is moving data from a text file to a database. We will read data from and write data to several different text-based formats, such as CSV and JSON. \n",
    "\n",
    "## Writing and reading files in python. \n",
    "\n",
    "###  To write data, you will use a library named <font color= blue> faker </font> . faker allows you to easily create fake data for common fields. You can generate an address by simply calling <font color= green > address() </font> , or a female name using name_female(). This will simplify the creation of fake data while at the same time making it more realistic. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing CSVs using the python CSV Library.\n",
    "\n",
    "> ##### Open a file in writing mode:-\n",
    ">> 'w' write \n",
    ">> 'a' --> apend \n",
    ">> 'r' --> read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The command below creates a file if it doesn't exist and makes it \"writing mode\" or \n",
    "#if the file exits already it changes it to \"writing mode\"\n",
    "output = open('myCSV.CSV', mode='w')\n",
    "\n",
    "\n",
    "# Note - writing more \"w\" writes data to a file after deleting data from a file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CSV_writer\n",
    "\n",
    "import csv\n",
    "\n",
    "mywriter = csv.writer(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create header to the file that you created and want to write data in\n",
    "\n",
    "header = ['name', 'age']\n",
    "mywriter.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write data to the file using a variable name \"data\"\n",
    "\n",
    "data0 = ['Bob Smith', 40]\n",
    "mywriter.writerow(data0)\n",
    "\n",
    "\n",
    "\n",
    "#I added the below three row data just to see more records in the file. \n",
    "data1 = ['Larry Smith', 35]\n",
    "mywriter.writerow(data1)\n",
    "\n",
    "data2 = ['Joe Peter', 26]\n",
    "mywriter.writerow(data2)\n",
    "\n",
    "data3 = ['Simon Sam', 46]\n",
    "mywriter.writerow(data3)\n",
    "\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This step is not in the book. In the book, \"cat mycsv.csv\" command is executed. \n",
    "#I added this so that I can see the result here in notebook. \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('myCSV.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import csv\n",
    "\n",
    "output=open('data.CSV','w')\n",
    "fake=Faker()\n",
    "header=['name','age','street','city','state','zip','lng','lat']\n",
    "mywriter=csv.writer(output)\n",
    "mywriter.writerow(header)\n",
    "for r in range(1000):\n",
    "    mywriter.writerow([fake.name(),fake.random_int(min=18, max=80, step=1), \n",
    "                       fake.street_address(), fake.city(),fake.state(),\n",
    "                       fake.zipcode(),fake.longitude(),fake.latitude()])\n",
    "\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This step \n",
    "\n",
    "df = pd.read_csv('data.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Reading CSVs\n",
    "\n",
    "Reading CSV is somewhat similar to writing csv file. The same steps are followed with slight modifications:\n",
    "\n",
    "\n",
    "The with statement automatically takes care of closing the file once it leaves the with block, even in cases of error. I highly recommend that you use the with statement as much as possible, as it allows for cleaner code and makes handling any unexpected errors easier for you.\n",
    "\n",
    "Most likely, you’ll also want to use the second positional argument, mode. This argument is a string that contains multiple characters to represent how you want to open the file. The default and most common is 'r', which represents opening the file in read-only mode as a text file:\n",
    "\n",
    "    Example\n",
    "> with open('dog_breeds.txt', 'r') as reader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('data.CSV') as f:\n",
    "    myreader = csv.DictReader(f)\n",
    "\n",
    "    headers=next(myreader)\n",
    "    \n",
    "    for row in myreader:\n",
    "        print(row['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We could also do it this way. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "f = open('data.CSV')\n",
    "\n",
    "myreader = csv.DictReader(f)\n",
    "\n",
    "headers =next(myreader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers =next(myreader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in myreader:\n",
    "    print(row['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and writing CSVs using pandas DataFrames\n",
    "\n",
    "pandas DataFrames are a powerful tool not only for reading and writing data but also for\n",
    "the querying and manipulation of data. It does require a larger overhead than the built-in\n",
    "CSV library, but there are times when it may be worth the trade-off. You may already have\n",
    "pandas installed, depending on your Python environment, but if you do not, you can\n",
    "install it with the following:\n",
    "\n",
    ">pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To read the top 10 rows of the file\n",
    "df.head(10)\n",
    "\n",
    "\n",
    "# This only shows the first 5 rows. \n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To read the bottom 10 rows of the file\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This command shows how many rows and columns\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This command shows what the column names are\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the datatypes of each columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#To get more information about the data\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the specific column\n",
    "country_df = df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.head() gives the first 5 rows\n",
    "print(country_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the last 5 rows\n",
    "print(country_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get more than one column\n",
    "subset = df[['name', 'age', 'street']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To het the 1st 5 rows of these columns\n",
    "print(subset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the last 5 columns of these columns\n",
    "print(subset.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get rows by index level\n",
    "#The code below prints the first row of the data frame\n",
    "df.loc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the 1st, 100th, and 1000th rows from the 1st, 4th and 6th comumns\n",
    "print(df.iloc[[0,99,999], [0,3,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the last row\n",
    "print(df.tail(n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the difference between \"loc\" and \"iloc\" --> The answer is [-1] and [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df.loc[:, ['name','age']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subset = df.iloc[:, [2, 4, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(subset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "# You can create a DataFrame in Python with the following steps:\n",
    "\n",
    "\n",
    "### Create a dictionary of data. A dictionary is a data structure that stores data as a key:value pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'Name':['Paul','Bob','Susan','Yolanda'], 'Age':[23,45,18,21]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('fromdf.CSV',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv('fromdf.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now have a CSV file with the contents of the <font color= red> DataFrame </font>. How we can use the\n",
    "contents of this DataFrame for executing SQL queries will be covered in the next chapter.\n",
    "They will become an important tool in your toolbox and the rest of the book will lean on\n",
    "them heavily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= white> skip </font>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Writing JSON with python\n",
    "\n",
    "\n",
    "Another common data format you will probably deal with is **JavaScript Object Notation\n",
    "<font color= red> (JSON) </font>**. You will see JSON most often when making calls to Application Programming\n",
    "Interfaces (APIs); however, it can exist as a file as well. How you handle the data is very\n",
    "similar no matter whether you read it from a file or an API. Python, as you learned with\n",
    "CSV, has a standard library for handling JSON data, not surprisingly named JSON–JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library and open the file you will write to. You also create the Faker object:\n",
    "\n",
    "from faker import Faker\n",
    "import json\n",
    "\n",
    "output=open('data.JSON','w')\n",
    "\n",
    "fake=Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata={}\n",
    "alldata['records']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(1000):\n",
    "    data={\"name\":fake.name(),\"age\":fake.random_int (min=18, max=80, step=1), \n",
    "          \"street\":fake.street_address(), \"city\":fake.city(),\n",
    "          \"state\":fake.state(), \"zip\":fake.zipcode(), \"lng\":float(fake.longitude()), \n",
    "          \"lat\":float(fake.latitude())}\n",
    "\n",
    "    alldata['records'].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(alldata,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.JSON','r') as f:\n",
    "    #breakpoint()\n",
    "    \n",
    "    data=json.load(f)\n",
    "    \n",
    "    data['records'][100]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_json('data.JSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
